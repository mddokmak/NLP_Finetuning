{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "from datasets import concatenate_datasets\n",
    "from torch import random\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "dataset1 = \"ArtifactAI/arxiv-math-instruct-50k\"\n",
    "dataset3 = \"zeroshot/arxiv-biology\"\n",
    "dataset4 = \"camel-ai/biology\"\n",
    "dataset5 = \"ayoubkirouane/arxiv-physics\"\n",
    "dataset6 = \"jilp00/YouToks-Instruct-Quantum-Physics-III\"\n",
    "dataset7 = \"jilp00/YouToks-Instruct-Quantum-Physics-II\"\n",
    "dataset8 = \"mjphayes/machine_learning_questions\"\n",
    "dataset9 = \"Mridul-Dixit/Machine-Learning-QA-Dataset\"\n",
    "dataset10 = \"jilp00/YouToks-Instruct-Thermodynamics-of-Materials\"\n",
    "dataset11 = \"whiteOUO/Ladder-machine-learning-QA\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "dataset1 = load_dataset(dataset1, split='train')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "{'question': 'What structure is classified as a definite lie algebra?',\n 'answer': 'A definite Lie algebra is a Lie algebra equipped with an inner product that is positive definite. Such an algebra is called a positive definite or a definite Lie algebra.'}"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# concatenate what is in question and answer in one column (they are strings)\n",
    "def concatenate_qa(line):\n",
    "    line['text'] = line['question'] + \"\\n\" + line['answer']\n",
    "    return line\n",
    "\n",
    "\n",
    "# apply the function to the dataset\n",
    "dataset1 = dataset1.map(concatenate_qa)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "# Drop question and answer columns\n",
    "dataset1 = dataset1.remove_columns(['question', 'answer'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "dataset3 = load_dataset(dataset3, split='train')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# concatenate what is in title and abstract in one column (they are strings)\n",
    "def concatenate_title_abstract(line):\n",
    "    line['text'] = line['title'] + \"\\n\" + line['abstract']\n",
    "    return line\n",
    "\n",
    "dataset3 = dataset3.map(concatenate_title_abstract)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "# Drop title and abstract columns\n",
    "dataset3 = dataset3.remove_columns(['title', 'abstract','id'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "dataset4 = load_dataset(dataset4, split='train')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "# concatenate what is in message_1 and message_2 in one column (they are strings)\n",
    "def concatenate_messages(line):\n",
    "    line['text'] = line['message_1'] + \"\\n\" + line['message_2']\n",
    "    return line\n",
    "\n",
    "dataset4 = dataset4.map(concatenate_messages)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# remove columns message_1 and message_2, role_1, topic\n",
    "dataset4 = dataset4.remove_columns(['message_1', 'message_2', 'role_1', 'topic;'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "# remove sub_topic column\n",
    "dataset4 = dataset4.remove_columns('sub_topic')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "dataset5 = load_dataset(dataset5, split='train')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "# concatenate what is in question and answer in one column (they are strings) with already existing function\n",
    "dataset5 = dataset5.map(concatenate_qa)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "# Drop question and answer columns\n",
    "dataset5 = dataset5.remove_columns(['question', 'answer'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "dataset6 = load_dataset(dataset6, split='train')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "# concatenate what is in question and response in one column (they are strings)\n",
    "def concatenate_qr(line):\n",
    "    line['text'] = line['question'] + \"\\n\" + line['response']\n",
    "    return line\n",
    "\n",
    "dataset6 = dataset6.map(concatenate_qr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "# Drop question and response columns and system_prompt, token_count\n",
    "dataset6 = dataset6.remove_columns(['question', 'response', 'system_prompt', 'token_count'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "dataset7 = load_dataset(dataset7, split='train')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "# concatenate what is in question and response in one column (they are strings)\n",
    "dataset7 = dataset7.map(concatenate_qr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "# Drop question and response columns and system_prompt, token_count,__index_level_0__\n",
    "dataset7 = dataset7.remove_columns(['question', 'response', 'system_prompt', 'token_count','__index_level_0__'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "dataset8 = load_dataset(dataset8, split='train')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "# concatenate what is in question and answer in one column (they are strings)\n",
    "dataset8 = dataset8.map(concatenate_qa)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "# Drop question and answer columns, __index_level_0__\n",
    "dataset8 = dataset8.remove_columns(['question', 'answer','__index_level_0__'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "dataset9 = load_dataset(dataset9, split='train')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "# concatenate what is in question and answer in one column (they are strings)\n",
    "dataset9 = dataset9.map(concatenate_qa)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "# Drop question and answer columns\n",
    "dataset9 = dataset9.remove_columns(['question', 'answer'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "dataset10 = load_dataset(dataset10, split='train')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "def filter_out_584(example, idx):\n",
    "    return idx != 584\n",
    "\n",
    "dataset10 = dataset10.filter(filter_out_584, with_indices=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "# Only take the column response which contains string but take only what is after \"\\nQUESTION:\" if it is not empty\n",
    "def take_response(line):\n",
    "    split = line['response'].split(\"\\nQUESTION:\")\n",
    "    if split[1] != \"\":\n",
    "        line['text'] = split[1]\n",
    "    return line\n",
    "\n",
    "dataset10 = dataset10.map(take_response)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "# remove token_count, response\n",
    "dataset10 = dataset10.remove_columns(['token_count', 'response'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "dataset11 = load_dataset(dataset11, split='train')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "# concatenate what is in Question and Answer in one column (they are strings)\n",
    "def concatenate_QA(line):\n",
    "    line['text'] = line['Question'] + \"\\n\" + line['Answer']\n",
    "    return line\n",
    "\n",
    "dataset11 = dataset11.map(concatenate_QA)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "# Drop Question and Answer columns\n",
    "dataset11 = dataset11.remove_columns(['Question', 'Answer'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "\n",
    "datasets = [dataset1, dataset3, dataset4, dataset5, dataset6, dataset7, dataset8, dataset9, dataset10, dataset11]\n",
    "\n",
    "# Concatenate all datasets\n",
    "datasets = concatenate_datasets(datasets)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "Creating json from Arrow format:   0%|          | 0/106 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ef5371430aa4d8b9fbade7bca14723c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "121209893"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the dataset as a JSON file\n",
    "datasets.to_json(\"datasets.json\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b9a4f6ca4b64516b3951f394eface69"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = 'datasets.json'\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset('json', data_files=file_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\41794\\anaconda3\\envs\\assMNLP\\lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/2992624 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3439fbe288c24e80a0b337b2b2471c9a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizerFast\n",
    "\n",
    "# Initialize the encoder and tokenizer\n",
    "ctx_encoder = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
    "ctx_tokenizer = DPRContextEncoderTokenizerFast.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
    "\n",
    "def embed(batch):\n",
    "    inputs = ctx_tokenizer(batch['text'], truncation=True, padding=True, return_tensors='pt')\n",
    "    #inputs = {k: v.to('cuda') for k, v in inputs.items()}  # Move inputs to GPU if available\n",
    "    with torch.no_grad():\n",
    "        embeddings = ctx_encoder(**inputs).pooler_output\n",
    "    return {'embeddings': embeddings.cpu().numpy()}\n",
    "\n",
    "# Process the dataset in batches\n",
    "dataset = dataset.map(embed, batched=True, batch_size=32)\n",
    "\n",
    "# Save the dataset with embeddings\n",
    "dataset.save_to_disk(\"encoded_dataset\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-assMNLP-py",
   "language": "python",
   "display_name": "Python [conda env:assMNLP] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
